{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a958a-e065-42ae-afe8-f9496835b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595b348-cdbc-4488-8360-691a8613c294",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc331ac-291c-4f48-8404-f491effebe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = '/arc/home/heestersnick/dwarforge/tables'\n",
    "models = '/arc/home/heestersnick/dwarforge/models'\n",
    "data_dir = '/arc/projects/unions/ssl/data/raw/tiles/dwarforge'\n",
    "training_data_file = 'umap_data_master.parquet'\n",
    "if training_data_file.endswith('.csv'):\n",
    "    training_data = pd.read_csv(os.path.join(tables, training_data_file))\n",
    "elif training_data_file.endswith('.parquet'):\n",
    "    training_data = pd.read_parquet(os.path.join(tables, training_data_file))\n",
    "    training_data['lsb_cfis_lsb-r'] = training_data['lsb_cfis_lsb-r'].fillna(0)\n",
    "    training_data.rename(columns={'lsb_cfis_lsb-r': 'lsb'}, inplace=True)\n",
    "    training_data.drop(columns=['lsb_whigs-g'], inplace=True)\n",
    "    training_data.drop(columns=['lsb_ps-i'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49311c63-4208-4501-a431-f1fa39ba5fd9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecefb16-e4e4-4602-9b2f-0dbf7c2d5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix', cmap='viridis'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    # cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    gs = plt.GridSpec(len(labels), len(labels) + 1, width_ratios=[4] * len(labels) + [0.1])\n",
    "    plt.figure(figsize=(len(labels) + 3, len(labels) + 3))\n",
    "    ax = sns.heatmap(\n",
    "        cm,\n",
    "        annot=False,\n",
    "        cmap=cmap,\n",
    "        cbar_kws={'shrink': 0.805},\n",
    "        square=True,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "    )\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if i == j:\n",
    "                ax.text(\n",
    "                    j + 0.5,\n",
    "                    i + 0.5,\n",
    "                    f'{cm[i, j]:d}\\n{cm_percentage[i, j]:.1f}%',\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    fontsize=10,\n",
    "                    color='black',\n",
    "                )\n",
    "            else:\n",
    "                ax.text(\n",
    "                    j + 0.5,\n",
    "                    i + 0.5,\n",
    "                    f'{cm[i, j]:d}\\n{cm_percentage[i, j]:.1f}%',\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    fontsize=10,\n",
    "                    color='white',\n",
    "                )\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    # plt.savefig('/home/nick/Documents/Candidacy_Exam/Presentation/Figures/'+'cm_w_percentage.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def classify_and_save_parquet(\n",
    "    parent_folder, random_forest_model, features, df_path_out, band='cfis_lsb-r'\n",
    "):\n",
    "    pattern = os.path.join(parent_folder, '*_*', band, 'CFIS_LSB.*.r_rebin_det_params.parquet')\n",
    "    positive_class_rows = []\n",
    "    for file in tqdm(glob(pattern)):\n",
    "        try:\n",
    "            filename = os.path.basename(file)\n",
    "            tile_numbers = filename.split('.')[1:3]\n",
    "            tile_id = f'({tile_numbers[0]}, {tile_numbers[1]})'\n",
    "\n",
    "            # Read the parquet file\n",
    "            df = pd.read_parquet(file)\n",
    "\n",
    "            # Select only the columns used for inference\n",
    "            X = df[features]\n",
    "\n",
    "            # Apply the random forest model\n",
    "            df['class'] = random_forest_model.predict(X)\n",
    "\n",
    "            # Aggregate rows where class = 1\n",
    "            positive_rows = df[df['class'] == 1].copy()\n",
    "            positive_rows['tile'] = tile_id  # Add file path for reference\n",
    "            positive_class_rows.append(positive_rows)\n",
    "\n",
    "            # Save the updated dataframe back to parquet\n",
    "            df.to_parquet(file, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error processing file {file}: {str(e)}')\n",
    "            continue\n",
    "\n",
    "    # Combine all positive class rows into a single DataFrame\n",
    "    if positive_class_rows:\n",
    "        all_positive_rows = pd.concat(positive_class_rows, ignore_index=True)\n",
    "        all_positive_rows.to_parquet(df_path_out, index=False)\n",
    "    else:\n",
    "        all_positive_rows = pd.DataFrame()\n",
    "\n",
    "    return all_positive_rows\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Additional metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    balanced_accuracy = (recall + specificity) / 2\n",
    "\n",
    "    # ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Average Precision (AP) summarizes a precision-recall curve\n",
    "    average_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall (Sensitivity): {recall:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Balanced Accuracy: {balanced_accuracy:.4f}')\n",
    "    print(f'ROC AUC: {roc_auc:.4f}')\n",
    "    print(f'Average Precision: {average_precision:.4f}')\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred, labels=['no dwarf', 'dwarf'])\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(f'Precision-Recall curve: AP={average_precision:0.2f}')\n",
    "    plt.show()\n",
    "\n",
    "    # Calibration curve\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(prob_pred, prob_true, marker='o')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.title('Calibration Curve')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sample_and_shuffle_data(df, label_column='lsb', neg_pos_ratio=3, random_state=42):\n",
    "    # Separate positive and negative examples\n",
    "    positive_df = df[df[label_column] == 1]\n",
    "    negative_df = df[df[label_column] == 0]\n",
    "\n",
    "    # Calculate the number of negative examples to keep\n",
    "    n_positive = len(positive_df)\n",
    "    n_negative_to_keep = n_positive * neg_pos_ratio\n",
    "\n",
    "    # Sample negative examples\n",
    "    if len(negative_df) > n_negative_to_keep:\n",
    "        negative_sample = negative_df.sample(n=int(n_negative_to_keep), random_state=random_state)\n",
    "    else:\n",
    "        negative_sample = negative_df  # Keep all if we don't have enough\n",
    "\n",
    "    # Combine positive examples with sampled negative examples\n",
    "    combined_df = pd.concat([positive_df, negative_sample])\n",
    "\n",
    "    # Shuffle the combined DataFrame\n",
    "    shuffled_df = combined_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    return shuffled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87fbd03-1f11-4a6d-9d8b-1a9f91a6dc2d",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7e015-1c31-4ef7-9789-4c07baf28890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['total_flux', 'mu_max', 'mu_median', 'mu_mean', 'n_pix', 're_arcsec', 'r_fwhm_arcsec', 'r_10_arcsec', 'r_25_arcsec', 'r_75_arcsec', 'r_90_arcsec', 'r_100_arcsec', 'A_arcsec', 'B_arcsec', 'axis_ratio', 'mag', 'mu', 'lsb']\n",
    "features = [\n",
    "    # \"total_flux_cfis_lsb-r\",\n",
    "    # \"mu_max_cfis_lsb-r\",\n",
    "    # \"mu_median_cfis_lsb-r\",\n",
    "    # \"mu_mean_cfis_lsb-r\",\n",
    "    're_arcsec_cfis_lsb-r',\n",
    "    # \"r_fwhm_arcsec_cfis_lsb-r\",\n",
    "    'r_10_arcsec_cfis_lsb-r',\n",
    "    'r_25_arcsec_cfis_lsb-r',\n",
    "    # \"r_75_arcsec_cfis_lsb-r\",\n",
    "    # \"r_90_arcsec_cfis_lsb-r\",\n",
    "    'r_100_arcsec_cfis_lsb-r',\n",
    "    # \"axis_ratio_cfis_lsb-r\",\n",
    "    # \"mag_cfis_lsb-r\",\n",
    "    # \"mu_cfis_lsb-r\",\n",
    "    # \"total_flux_whigs-g\",\n",
    "    # \"mu_max_whigs-g\",\n",
    "    # \"mu_median_whigs-g\",\n",
    "    # \"mu_mean_whigs-g\",\n",
    "    're_arcsec_whigs-g',\n",
    "    # \"r_fwhm_arcsec_whigs-g\",\n",
    "    'r_10_arcsec_whigs-g',\n",
    "    'r_25_arcsec_whigs-g',\n",
    "    # \"r_75_arcsec_whigs-g\",\n",
    "    # \"r_90_arcsec_whigs-g\",\n",
    "    'r_100_arcsec_whigs-g',\n",
    "    # \"axis_ratio_whigs-g\",\n",
    "    # \"mag_whigs-g\",\n",
    "    # \"mu_whigs-g\",\n",
    "    # \"total_flux_ps-i\",\n",
    "    # \"mu_max_ps-i\",\n",
    "    # \"mu_median_ps-i\",\n",
    "    # \"mu_mean_ps-i\",\n",
    "    're_arcsec_ps-i',\n",
    "    # \"r_fwhm_arcsec_ps-i\",\n",
    "    'r_10_arcsec_ps-i',\n",
    "    'r_25_arcsec_ps-i',\n",
    "    # \"r_75_arcsec_ps-i\",\n",
    "    # \"r_90_arcsec_ps-i\",\n",
    "    'r_100_arcsec_ps-i',\n",
    "    # \"axis_ratio_ps-i\",\n",
    "    # \"mag_ps-i\",\n",
    "    # \"mu_ps-i\",\n",
    "    'lsb',\n",
    "]\n",
    "dwarf_column = 'lsb'\n",
    "training_df = training_data[features]\n",
    "training_df = sample_and_shuffle_data(training_df, neg_pos_ratio=2.0)\n",
    "X, y = training_df.drop(columns=[dwarf_column]), training_df[dwarf_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=np.random.randint(99)\n",
    ")\n",
    "print(\n",
    "    f'Using {len(training_df)} examples. {np.count_nonzero(y == 1)} positive and {np.count_nonzero(y == 0)} negative ones.'\n",
    ")\n",
    "print(f'{len(X_train)} are used for training, {len(X_test)} for testing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ca528-7621-4850-b543-a2f71c73c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier(\n",
    "#     n_estimators=1000, random_state=np.random.randint(98)\n",
    "# )\n",
    "# # Train the classifier\n",
    "# start_time = time.time()\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "# print(\"Training done! Finished in {} minutes.\".format((time.time() - start_time) / 60))\n",
    "# # Make predictions on the test set\n",
    "# y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b5038-33fe-4dc8-b74e-d6306fb85a29",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c75bb-c4a4-428a-8722-2e5c5725dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b47412-abc4-4b45-a3a4-cea1290a9993",
   "metadata": {},
   "source": [
    "# Grid search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4a3ca-d9cf-41cd-9745-c1b487f4ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1, 1: 2}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(50, 200, 15),\n",
    "    'max_features': np.arange(0.1, 1, 0.1),\n",
    "    'max_depth': [3, 5, 7, 9, 12],\n",
    "    'max_samples': np.arange(0.2, 1, 0.2),\n",
    "    'class_weight': [class_weights, 'balanced', 'balanced_subsample', None],\n",
    "}\n",
    "\n",
    "model = RSCV(RandomForestClassifier(), param_grid, n_iter=30, cv=5, scoring='f1').fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "model = model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428a952-a056-4998-abfc-0dfe507edd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf274a4-82dd-42f8-9576-19b56b48593d",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e9829-db6a-4f63-8226-aaad7a28852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c4a93-d3a1-4848-921b-1403f269209b",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d51f6-6d75-4d6a-aba1-44dac69f71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Feature': list(X_train.columns),\n",
    "        'Importance': (importances / np.sum(importances)),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by='Importance', ascending=False\n",
    ").reset_index(drop=True)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a69e6-cbf4-48ca-93b9-e591619dac7a",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b70408-595c-4eba-b675-b16785399aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "y_pred = model.predict(X_test)\n",
    "plot_confusion_matrix(y_test, y_pred, labels=['no dwarf', 'dwarf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d645af3-bee5-414d-87eb-11362aa42cd1",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207c56d-fae1-4cf0-b89d-f38bb40d7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(model, os.path.join(models, 'random_forest_model_4x_None.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94933783-554c-4653-b067-dabbaac2952f",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ec873-478b-4d45-96ea-dfcf37ecd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(os.path.join(models, 'random_forest_model_1033.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7ebec-efb3-48f8-a4a3-c1e37a56667f",
   "metadata": {},
   "source": [
    "# Apply the Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b78e8e-108b-4fba-af9c-beb57f71fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class_df_path = os.path.join(tables, 'pos_class.parquet')\n",
    "# classify_and_save_parquet(data_dir, loaded_model, features=features, df_path_out=pos_class_df_path, band='cfis_lsb-r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99374007-9c31-41ee-a371-6a0cc5e88d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = pd.read_parquet(pos_class_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84ebd6-f5ca-41c3-932c-ebc2d3ae0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins = np.arange(0.001, 20, 0.1)\n",
    "plt.hist(pos_class.r_10_arcsec.values, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784376f-76a6-4232-8b03-0c9da4191244",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwarfs = training_data[training_data['lsb'] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38540711-31d0-47cf-ab01-58bdc1b951f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins = np.arange(0, 20, 0.1)\n",
    "plt.hist(dwarfs.r_10_arcsec.values, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b70a8-a8a6-4903-82c8-6b7992fd0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(dwarfs['r_10_arcsec'].values == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047057f7-f09d-404b-b13c-8c19d269d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(dwarfs['r_10_arcsec'].values > 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f39b20-41d0-40a7-b912-c2c0d7691605",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(pos_class['re_arcsec'].values <= 1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e112-4d54-4084-900e-310e60acc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2075db-c374-4df7-8d3d-4aa92942cf48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
