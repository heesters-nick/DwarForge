{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5664747-449e-4bc1-9f21-7309909d8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import ast\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy.spatial import cKDTree\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1e348-b340-45c1-b859-6a583a0aea77",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d2e2c3-3bcb-4b95-81b5-b278f2db876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/arc/projects/unions/ssl/data/raw/tiles/dwarforge'\n",
    "table_dir = '/arc/home/heestersnick/dwarforge/tables'\n",
    "dwarf_cat_file = 'all_known_dwarfs_v2_processed.csv'\n",
    "dwarf_cat = pd.read_csv(os.path.join(table_dir, dwarf_cat_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c614a-65f7-4957-b8ef-d65419f5253a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98df34b1-5b63-425c-86b8-3d7d5279c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zfill_tile(tile):\n",
    "    return f'{str(tile[0]).zfill(3)}_{str(tile[1]).zfill(3)}'\n",
    "\n",
    "def labels_to_df(parent_folder, tile_list, dwarf_df):\n",
    "    k = 0\n",
    "    unmatched_dwarf_counter = 0\n",
    "    unmatched_tile_counter = 0\n",
    "    additional_dwarf_counter = 0\n",
    "    for tile in tqdm(tile_list):\n",
    "        # Convert tile tuple to folder name format\n",
    "        folder_name = zfill_tile(tile)\n",
    "        \n",
    "        # Construct the full path to the parquet file\n",
    "        tile_nums_zfill = folder_name.split('_')\n",
    "        file_path = os.path.join(parent_folder, folder_name, \"cfis_lsb-r\", f\"CFIS_LSB.{tile_nums_zfill[0]}.{tile_nums_zfill[1]}.r_rebin_det_params.parquet\")\n",
    "        fits_name = f'CFIS_LSB.{tile_nums_zfill[0]}.{tile_nums_zfill[1]}.r_rebin_seg.fits'\n",
    "        fits_path = os.path.join(parent_folder, folder_name, \"cfis_lsb-r\", fits_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Attempt to read the parquet file\n",
    "                det_df = pd.read_parquet(file_path)\n",
    "                det_df_updated = det_df.copy()\n",
    "                dwarfs_in_tile = dwarf_df[dwarf_df['tile'] == str(tile)].reset_index(drop=True)\n",
    "                _, header = open_fits(fits_path, fits_ext=0)\n",
    "                additional_dwarfs = check_objects_in_neighboring_tiles(str(tile), dwarf_df, header)\n",
    "\n",
    "                if not additional_dwarfs.empty:\n",
    "                    dwarfs_in_tile = pd.concat([dwarfs_in_tile, additional_dwarfs]).reset_index(drop=True)\n",
    "\n",
    "                det_idx_lsb, lsb_matches, lsb_unmatches, _ = match_cats(det_df_updated, dwarfs_in_tile, tile, header, max_sep=15.0)\n",
    "\n",
    "                # add lsb labels to detections dataframe\n",
    "                det_df_updated['lsb'] = np.nan\n",
    "                det_df_updated['ID_known'] = np.nan\n",
    "\n",
    "                if len(det_idx_lsb) > 0:\n",
    "                    print(f'Found {len(det_idx_lsb)} lsb detections for tile {tile}.')\n",
    "                    det_df_updated.loc[det_idx_lsb, 'lsb'] = 1\n",
    "                    # Initialize the column to accept strings\n",
    "                    det_df_updated['ID_known'] = det_df_updated['ID_known'].astype(object)\n",
    "                    det_df_updated.loc[det_idx_lsb, 'ID_known'] = lsb_matches['ID'].values\n",
    "                    # print(\n",
    "                    #     f'Added {np.count_nonzero(~np.isnan(det_df_updated[\"lsb\"]))} LSB labels to the detection dataframe for tile {tile}.'\n",
    "                    # )\n",
    "                    k += 1\n",
    "                    additional_dwarf_counter += len(additional_dwarfs)\n",
    "\n",
    "                if len(lsb_unmatches) > 0:\n",
    "                    print(f'Found {len(lsb_unmatches)} unmatched dwarf for tile: {tile}.')\n",
    "                    unmatched_tile_counter += 1\n",
    "                    unmatched_dwarf_counter += len(lsb_unmatches)\n",
    "\n",
    "                # Save updated dataframe\n",
    "                det_df_updated.to_parquet(file_path, index=False)\n",
    "            except Exception as e:\n",
    "                print(f'Something went wrong for tile {tile}: {e}')\n",
    "    print(f'Was able to match {k}/{len(tile_list)} tiles.')\n",
    "    print(f'There were {unmatched_dwarf_counter} unmatched dwarfs in {unmatched_tile_counter} tiles.')\n",
    "    print(f'{additional_dwarf_counter} dwarfs are in multiple tiles.')\n",
    "\n",
    "def open_fits(file_path, fits_ext):\n",
    "    \"\"\"\n",
    "    Open fits file and return data and header.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): name of the fits file\n",
    "        fits_ext (int): extension of the fits file\n",
    "\n",
    "    Returns:\n",
    "        data (numpy.ndarray): image data\n",
    "        header (fits header): header of the fits file\n",
    "    \"\"\"\n",
    "    # logger.debug(f'Opening fits file {os.path.basename(file_path)}..')\n",
    "    with fits.open(file_path, memmap=True) as hdul:\n",
    "        data = hdul[fits_ext].data.astype(np.float32)  # type: ignore\n",
    "        header = hdul[fits_ext].header  # type: ignore\n",
    "    # logger.debug(f'Fits file {os.path.basename(file_path)} opened.')\n",
    "    return data, header\n",
    "                \n",
    "def check_objects_in_neighboring_tiles(tile, dwarfs_df, header):\n",
    "    wcs = WCS(header)\n",
    "    # Get neighboring tile numbers\n",
    "    neighboring_tiles = get_neighboring_tile_numbers(tile)\n",
    "\n",
    "    # Filter dwarfs in neighboring tiles\n",
    "    neighboring_dwarfs = dwarfs_df[dwarfs_df['tile'].isin(neighboring_tiles)]\n",
    "\n",
    "    # Check which of these dwarfs are actually within the current tile's boundaries\n",
    "    dwarfs_in_current_tile = neighboring_dwarfs[\n",
    "        neighboring_dwarfs.apply(\n",
    "            lambda row: wcs.footprint_contains(\n",
    "                SkyCoord(row['ra'], row['dec'], unit='deg', frame='icrs')\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return dwarfs_in_current_tile\n",
    "\n",
    "def get_neighboring_tile_numbers(tile):\n",
    "    tile = ast.literal_eval(tile)\n",
    "    x, y = map(int, tile)\n",
    "    neighbors = [\n",
    "        (x - 1, y - 1),\n",
    "        (x - 1, y),\n",
    "        (x - 1, y + 1),\n",
    "        (x, y - 1),\n",
    "        (x, y + 1),\n",
    "        (x + 1, y - 1),\n",
    "        (x + 1, y),\n",
    "        (x + 1, y + 1),\n",
    "    ]\n",
    "    return [f'({nx:03d}, {ny:03d})' for nx, ny in neighbors if 0 <= nx < 1000 and 0 <= ny < 1000]\n",
    "\n",
    "def dwarfs_to_df(parent_folder):\n",
    "    # Pattern to match all relevant parquet files\n",
    "    pattern = os.path.join(parent_folder, \"*_*\", \"cfis_lsb-r\", \"CFIS_LSB.*.r_rebin_det_params.parquet\")\n",
    "    \n",
    "    # List to store filtered dataframes\n",
    "    filtered_dfs = []\n",
    "    \n",
    "    # Iterate through all matching files\n",
    "    for file in tqdm(glob(pattern)):\n",
    "        try:\n",
    "            # Attempt to read the parquet file\n",
    "            df = pd.read_parquet(file)\n",
    "            # Check if 'label' column exists\n",
    "            if 'lsb' in df.columns:\n",
    "                # Filter rows where label is 1\n",
    "                df_filtered = df[df['lsb'] == 1]\n",
    "                \n",
    "                if not df_filtered.empty:\n",
    "                    filtered_dfs.append(df_filtered)\n",
    "            # If 'label' column doesn't exist, we skip this file\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # The file is automatically closed after reading\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    if filtered_dfs:\n",
    "        final_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "        return final_df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty dataframe if no data found\n",
    "\n",
    "def gather_training_data(parent_folder, band='cfis_lsb-r', n_neighbors=1):\n",
    "    pattern = os.path.join(parent_folder, \"*_*\", band, \"CFIS_LSB.*.r_rebin_det_params.parquet\")\n",
    "    \n",
    "    all_examples = []\n",
    "    \n",
    "    for file in tqdm(glob(pattern)):\n",
    "        try:\n",
    "            filename = os.path.basename(file)\n",
    "            tile_numbers = filename.split('.')[1:3]\n",
    "            tile_id = f\"{tile_numbers[0]}.{tile_numbers[1]}\"\n",
    "            \n",
    "            df = pd.read_parquet(file)\n",
    "            \n",
    "            if 'lsb' in df.columns:\n",
    "                positive_examples = df[df['lsb'] == 1].copy()\n",
    "                potential_negatives = df[df['lsb'].isna()].copy()\n",
    "                \n",
    "                if not positive_examples.empty and not potential_negatives.empty:\n",
    "                    nn = NearestNeighbors(n_neighbors=len(potential_negatives), metric='euclidean')\n",
    "                    nn.fit(potential_negatives[['ra', 'dec']])\n",
    "                    \n",
    "                    used_negatives = set()  # Set to keep track of used negative examples in this field\n",
    "                    all_file_examples = []\n",
    "                    \n",
    "                    for idx, lsb_obj in positive_examples.iterrows():\n",
    "                        lsb_df = pd.DataFrame({'ra': [lsb_obj['ra']], 'dec': [lsb_obj['dec']]})\n",
    "                        \n",
    "                        distances, indices = nn.kneighbors(lsb_df)\n",
    "                        \n",
    "                        # Find n_neighbors unique negative examples within this field\n",
    "                        unique_negatives = []\n",
    "                        for index in indices[0]:\n",
    "                            if index not in used_negatives:\n",
    "                                unique_negatives.append(index)\n",
    "                                used_negatives.add(index)\n",
    "                                if len(unique_negatives) == n_neighbors:\n",
    "                                    break\n",
    "                        \n",
    "                        # If we couldn't find enough unique negatives, continue to the next positive example\n",
    "                        if len(unique_negatives) < n_neighbors:\n",
    "                            continue\n",
    "                        \n",
    "                        nearest_neighbors = potential_negatives.iloc[unique_negatives].copy()\n",
    "                        \n",
    "                        lsb_obj['example_id'] = f\"{tile_id}.{lsb_obj['ID']}\"\n",
    "                        \n",
    "                        nearest_neighbors['example_id'] = nearest_neighbors['ID'].apply(lambda x: f\"{tile_id}.{x}\")\n",
    "                        nearest_neighbors['lsb'] = 0  # Set to 0 for negative examples\n",
    "                        nearest_neighbors['associated_lsb_ra'] = lsb_obj['ra']\n",
    "                        nearest_neighbors['associated_lsb_dec'] = lsb_obj['dec']\n",
    "                        \n",
    "                        all_file_examples.append(pd.concat([lsb_obj.to_frame().T, nearest_neighbors]))\n",
    "                    \n",
    "                    if all_file_examples:\n",
    "                        all_examples.append(pd.concat(all_file_examples))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if all_examples:\n",
    "        final_df = pd.concat(all_examples, ignore_index=True)\n",
    "        return final_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def create_cartesian_kdtree(ra, dec):\n",
    "    \"\"\"\n",
    "    Create a KD-Tree using Cartesian coordinates converted from RA and Dec.\n",
    "    \n",
    "    :param ra: Right Ascension in degrees\n",
    "    :param dec: Declination in degrees\n",
    "    :return: cKDTree object and the corresponding SkyCoord object\n",
    "    \"\"\"\n",
    "    coords = SkyCoord(ra, dec, unit='deg', frame='icrs')\n",
    "    xyz = coords.cartesian.xyz.value.T\n",
    "    tree = cKDTree(xyz)\n",
    "    return tree, coords\n",
    "\n",
    "def match_cats(df_det, df_label, tile, pixel_scale, max_sep=15.0, re_multiplier=4.0):\n",
    "    tree, _ = create_cartesian_kdtree(df_det['ra'].values, df_det['dec'].values)\n",
    "    matches = []\n",
    "    potential_matches_df = pd.DataFrame()\n",
    "    for idx, known in df_label.iterrows():\n",
    "        known_coords = SkyCoord(known['ra'], known['dec'], unit='deg')\n",
    "        known_coords_xyz = known_coords.cartesian.xyz.value\n",
    "        \n",
    "        # Calculate base search radius in degrees\n",
    "        base_search_radius = max_sep / 3600  # Convert arcseconds to degrees\n",
    "        \n",
    "        # Adaptive search radius (if 're' is available)\n",
    "        if 're' in known and known['re'] is not None and not np.isnan(known['re']) and known['re'] > 0:\n",
    "            adaptive_radius = known['re'] * re_multiplier / 3600  # Convert to degrees\n",
    "            search_radius = max(base_search_radius, adaptive_radius)\n",
    "        else:\n",
    "            search_radius = base_search_radius\n",
    "            \n",
    "        search_radius_chord = 2 * np.sin(np.deg2rad(search_radius) / 2)\n",
    "        \n",
    "        potential_match_indices = tree.query_ball_point(known_coords_xyz, search_radius_chord)\n",
    "        potential_matches = df_det.iloc[potential_match_indices]\n",
    "        \n",
    "        print(f'potential matches for {known[\"ID\"]}: {len(potential_matches)}')\n",
    "        \n",
    "        potential_matches_df = pd.concat([potential_matches_df, potential_matches])\n",
    "        if len(potential_matches) > 0:\n",
    "            potential_matches_coords = SkyCoord(potential_matches['ra'], potential_matches['dec'], unit='deg')\n",
    "            distances = known_coords.separation(potential_matches_coords).arcsec\n",
    "            max_n_pix = potential_matches['n_pix'].max()\n",
    "            max_mu = potential_matches['mu'].max()\n",
    "            scores = []\n",
    "            for i, det in potential_matches.iterrows():\n",
    "                size_score = np.log1p(det['n_pix']) / np.log1p(max_n_pix)\n",
    "                lsb_score = det['mu'] / max_mu\n",
    "                distance = distances[potential_matches.index.get_loc(i)]\n",
    "                distance_score = 1 - (distance / (3600 * search_radius))  # Normalized distance score\n",
    "                score = (\n",
    "                    lsb_score * 0.2\n",
    "                    + size_score * 0.4\n",
    "                    + distance_score * 0.4\n",
    "                )\n",
    "                print(f'object: {det[\"ID\"]}; lsb score: {lsb_score:.4f}, size score: {size_score:.4f}, distance score: {distance_score:.4f}')\n",
    "                print(f'object: {det[\"ID\"]}; total score: {score:.4f}; distance: {distance:.2f} arcsec')\n",
    "                scores.append((i, score, distance))\n",
    "            best_match = max(scores, key=lambda x: x[1])\n",
    "            matches.append((idx, best_match[0], best_match[2]))\n",
    "    \n",
    "    if matches:\n",
    "        label_match_idx, det_match_idx, match_distances = zip(*matches)\n",
    "    else:\n",
    "        label_match_idx, det_match_idx, match_distances = [], [], []\n",
    "    label_matches = df_label.loc[list(label_match_idx)].reset_index(drop=True)\n",
    "    label_unmatches = df_label.drop(list(label_match_idx)).reset_index(drop=True)\n",
    "    det_matches = df_det.loc[list(det_match_idx)].reset_index(drop=True)\n",
    "    det_matches['match_distance'] = match_distances\n",
    "    return list(det_match_idx), label_matches, label_unmatches, det_matches\n",
    "\n",
    "def get_tile_list(dwarf_cat):\n",
    "    tiles = dwarf_cat['tile'].values\n",
    "    non_nan_tiles = [x for x in tiles if x is not np.nan]\n",
    "    str_to_tuple = [ast.literal_eval(item) for item in non_nan_tiles]\n",
    "    unique_tiles = list(set(str_to_tuple))\n",
    "    return unique_tiles\n",
    "\n",
    "def check_bands(bands_str, to_check):\n",
    "    if isinstance(bands_str, str):\n",
    "        try:\n",
    "            bands_list = ast.literal_eval(bands_str)\n",
    "            return all(band in bands_list for band in to_check)\n",
    "        except:\n",
    "            return False\n",
    "    return False  # Return False for NaN values\n",
    "\n",
    "def check_availability(dwarf_cat, check_for_bands):\n",
    "    df_select = dwarf_cat.loc[(~dwarf_cat['tile'].isna()) & (dwarf_cat['bands'].apply(lambda x: check_bands(x, check_for_bands)))].reset_index(drop=True)\n",
    "    return df_select, len(df_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f321a6-bb15-4364-b3fc-b49447a767a8",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f09e392-a45a-4f12-b526-49449a4adf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_list = get_tile_list(dwarf_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f94d3b6-f201-4ec5-ac9c-cffbe6ab46e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarf_cat['bands'][0] in 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e29f66d-38db-46e9-a5e5-d827f2dbe40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [host, ID, ra, dec, morph, re, zspec, tile, x, y, bands, n_bands, cutout]\n",
       " Index: [],\n",
       " 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_availability(dwarf_cat, ['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "391b9286-11e2-4c31-87a7-52fea8718811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>ID</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>morph</th>\n",
       "      <th>re</th>\n",
       "      <th>zspec</th>\n",
       "      <th>tile</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>bands</th>\n",
       "      <th>n_bands</th>\n",
       "      <th>cutout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGC5457</td>\n",
       "      <td>[MVA2014] DF 4</td>\n",
       "      <td>211.89083</td>\n",
       "      <td>54.71089</td>\n",
       "      <td>UDG</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(246, 289)</td>\n",
       "      <td>4120.276396</td>\n",
       "      <td>9087.340522</td>\n",
       "      <td>ugriz</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGC5457</td>\n",
       "      <td>[MVA2014] DF 5</td>\n",
       "      <td>211.11710</td>\n",
       "      <td>55.61670</td>\n",
       "      <td>UDG</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(239, 291)</td>\n",
       "      <td>3492.105870</td>\n",
       "      <td>7263.024500</td>\n",
       "      <td>ugriz</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGC5457</td>\n",
       "      <td>[MVA2014] DF 6</td>\n",
       "      <td>212.07792</td>\n",
       "      <td>55.19183</td>\n",
       "      <td>UDG</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(243, 290)</td>\n",
       "      <td>2244.034195</td>\n",
       "      <td>8722.400179</td>\n",
       "      <td>ugriz</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NGC5457</td>\n",
       "      <td>[MVA2014] DF 7</td>\n",
       "      <td>211.44792</td>\n",
       "      <td>55.13258</td>\n",
       "      <td>UDG</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(243, 290)</td>\n",
       "      <td>9219.451934</td>\n",
       "      <td>7580.774126</td>\n",
       "      <td>ugriz</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NGC253</td>\n",
       "      <td>NGC247</td>\n",
       "      <td>11.78340</td>\n",
       "      <td>-20.75700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.882787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14095</th>\n",
       "      <td>NGC7541</td>\n",
       "      <td>LS-357669-3767</td>\n",
       "      <td>348.87450</td>\n",
       "      <td>4.61310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(696, 189)</td>\n",
       "      <td>8893.878219</td>\n",
       "      <td>7192.314564</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14096</th>\n",
       "      <td>NGC7541</td>\n",
       "      <td>LS-357668-2728</td>\n",
       "      <td>348.62140</td>\n",
       "      <td>4.50730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(695, 189)</td>\n",
       "      <td>4094.690157</td>\n",
       "      <td>5141.495530</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>NGC7541</td>\n",
       "      <td>LS-360540-737</td>\n",
       "      <td>348.55460</td>\n",
       "      <td>4.91510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(694, 190)</td>\n",
       "      <td>576.261089</td>\n",
       "      <td>3355.482606</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>NGC7716</td>\n",
       "      <td>NSA-31702</td>\n",
       "      <td>354.35080</td>\n",
       "      <td>0.39100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(709, 181)</td>\n",
       "      <td>8152.874666</td>\n",
       "      <td>2887.720956</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14099</th>\n",
       "      <td>NGC7716</td>\n",
       "      <td>NSA-31683</td>\n",
       "      <td>354.19520</td>\n",
       "      <td>0.62340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(708, 181)</td>\n",
       "      <td>1478.638313</td>\n",
       "      <td>7391.428576</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14100 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          host              ID         ra       dec morph          re  zspec  \\\n",
       "0      NGC5457  [MVA2014] DF 4  211.89083  54.71089   UDG   28.000000    NaN   \n",
       "1      NGC5457  [MVA2014] DF 5  211.11710  55.61670   UDG   38.000000    NaN   \n",
       "2      NGC5457  [MVA2014] DF 6  212.07792  55.19183   UDG   22.000000    NaN   \n",
       "3      NGC5457  [MVA2014] DF 7  211.44792  55.13258   UDG   20.000000    NaN   \n",
       "4       NGC253          NGC247   11.78340 -20.75700   NaN  247.882787    NaN   \n",
       "...        ...             ...        ...       ...   ...         ...    ...   \n",
       "14095  NGC7541  LS-357669-3767  348.87450   4.61310   NaN         NaN    NaN   \n",
       "14096  NGC7541  LS-357668-2728  348.62140   4.50730   NaN         NaN    NaN   \n",
       "14097  NGC7541   LS-360540-737  348.55460   4.91510   NaN         NaN    NaN   \n",
       "14098  NGC7716       NSA-31702  354.35080   0.39100   NaN         NaN    NaN   \n",
       "14099  NGC7716       NSA-31683  354.19520   0.62340   NaN         NaN    NaN   \n",
       "\n",
       "             tile            x            y  bands  n_bands  cutout  \n",
       "0      (246, 289)  4120.276396  9087.340522  ugriz        5       0  \n",
       "1      (239, 291)  3492.105870  7263.024500  ugriz        5       0  \n",
       "2      (243, 290)  2244.034195  8722.400179  ugriz        5       0  \n",
       "3      (243, 290)  9219.451934  7580.774126  ugriz        5       0  \n",
       "4             NaN          NaN          NaN    NaN        0       0  \n",
       "...           ...          ...          ...    ...      ...     ...  \n",
       "14095  (696, 189)  8893.878219  7192.314564      u        1       0  \n",
       "14096  (695, 189)  4094.690157  5141.495530      u        1       0  \n",
       "14097  (694, 190)   576.261089  3355.482606      u        1       0  \n",
       "14098  (709, 181)  8152.874666  2887.720956      u        1       0  \n",
       "14099  (708, 181)  1478.638313  7391.428576      u        1       0  \n",
       "\n",
       "[14100 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwarf_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b4bf7-7124-44fc-ab4e-4a57346de1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4f5aa-c0ee-41a6-a85e-a87db57af05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d3a23d-5a4e-44ea-b75d-890d12ac049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881241c3b3c44a5281207a222689a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = gather_training_data(data_dir, band='cfis_lsb-r', n_neighbors=10)\n",
    "training_data.to_csv(os.path.join(table_dir, 'training_data_10x_rf.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90722a2-dff0-42dd-9ba3-6108eb94966b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11363"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09152e96-e0d6-4837-a06c-f5ab975dc051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
