{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b6832-e55f-4513-9753-ff9c826a5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from scipy.ndimage import binary_dilation, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2943a2-413c-4657-a536-0c4a9dcc5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a8443-bcaf-4020-815f-29e96d635acf",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453df67-85fe-4ad8-923c-dfa0ec2f7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/arc/projects/unions/ssl/data/raw/tiles/dwarforge'\n",
    "main_dir = '/arc/home/heestersnick/dwarforge'\n",
    "table_dir = os.path.join(main_dir, 'tables')\n",
    "figure_dir = os.path.join(main_dir, 'figures')\n",
    "tile_info_dir = os.path.join(main_dir, 'tile_info')\n",
    "train_df = pd.read_csv(os.path.join(table_dir, 'train_df.csv'))\n",
    "class_df = pd.read_csv(os.path.join(table_dir, 'class_df.csv'))\n",
    "master = pd.read_parquet('/arc/home/heestersnick/dwarforge/tables/unions_master.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5860e-8825-4b8d-b3f1-85a29b95c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()['unique_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdeba7-ed95-4055-8c0f-05fefae27d99",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbdeea-477a-429b-be9e-20cc1d7f57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "band_dictionary = {\n",
    "    'cfis-u': {\n",
    "        'name': 'CFIS',\n",
    "        'band': 'u',\n",
    "        'vos': 'vos:cfis/tiles_DR5/',\n",
    "        'suffix': '.u.fits',\n",
    "        'delimiter': '.',\n",
    "        'fits_ext': 0,\n",
    "        'zfill': 3,\n",
    "        'zp': 30.0,\n",
    "    },\n",
    "    'whigs-g': {\n",
    "        'name': 'calexp-CFIS',\n",
    "        'band': 'g',\n",
    "        'vos': 'vos:cfis/whigs/stack_images_CFIS_scheme/',\n",
    "        'suffix': '.fits',\n",
    "        'delimiter': '_',\n",
    "        'fits_ext': 1,\n",
    "        'zfill': 0,\n",
    "        'zp': 27.0,\n",
    "    },\n",
    "    'cfis_lsb-r': {\n",
    "        'name': 'CFIS_LSB',\n",
    "        'band': 'r',\n",
    "        'vos': 'vos:cfis/tiles_LSB_DR5/',\n",
    "        'suffix': '.r.fits',\n",
    "        'delimiter': '.',\n",
    "        'fits_ext': 0,\n",
    "        'zfill': 3,\n",
    "        'zp': 30.0,\n",
    "    },\n",
    "    'ps-i': {\n",
    "        'name': 'PS-DR3',\n",
    "        'band': 'i',\n",
    "        'vos': 'vos:cfis/panstarrs/DR3/tiles/',\n",
    "        'suffix': '.i.fits',\n",
    "        'delimiter': '.',\n",
    "        'fits_ext': 0,\n",
    "        'zfill': 3,\n",
    "        'zp': 30.0,\n",
    "    },\n",
    "    'wishes-z': {\n",
    "        'name': 'WISHES',\n",
    "        'band': 'z',\n",
    "        'vos': 'vos:cfis/wishes_1/coadd/',\n",
    "        'suffix': '.z.fits',\n",
    "        'delimiter': '.',\n",
    "        'fits_ext': 1,\n",
    "        'zfill': 0,\n",
    "        'zp': 27.0,\n",
    "    },\n",
    "    'ps-z': {\n",
    "        'name': 'PSS.DR4',\n",
    "        'band': 'ps-z',\n",
    "        'vos': 'vos:cfis/panstarrs/DR4/resamp/',\n",
    "        'suffix': '.z.fits',\n",
    "        'delimiter': '.',\n",
    "        'fits_ext': 0,\n",
    "        'zfill': 3,\n",
    "        'zp': 30.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def read_h5(file_path, needed_datasets=['ra', 'dec', 'images', 'zoobot_pred']):\n",
    "    \"\"\"\n",
    "    Reads cutout data from HDF5 file with optimized dataset selection\n",
    "\n",
    "    Args:\n",
    "        file_path: path to HDF5 file\n",
    "        needed_datasets: list of datasets to read (None = read all)\n",
    "\n",
    "    Returns:\n",
    "        cutout_data: dictionary with requested datasets\n",
    "    \"\"\"\n",
    "    cutout_data = {}\n",
    "\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Determine which datasets to load\n",
    "        if needed_datasets is None:\n",
    "            datasets_to_read = f.keys()\n",
    "        else:\n",
    "            datasets_to_read = [d for d in needed_datasets if d in f]\n",
    "\n",
    "        # Loop through and load only needed datasets\n",
    "        for dataset_name in datasets_to_read:\n",
    "            if dataset_name == 'images':\n",
    "                data = np.nan_to_num(np.array(f[dataset_name]), nan=0.0)\n",
    "            else:\n",
    "                data = np.array(f[dataset_name])\n",
    "            cutout_data[dataset_name] = data\n",
    "\n",
    "    return cutout_data\n",
    "\n",
    "\n",
    "def get_tile_numbers(name):\n",
    "    \"\"\"\n",
    "    Extract tile numbers from tile name\n",
    "    :param name: .fits file name of a given tile\n",
    "    :return two three digit tile numbers\n",
    "    \"\"\"\n",
    "\n",
    "    if name.startswith('calexp'):\n",
    "        pattern = re.compile(r'(?<=[_-])(\\d+)(?=[_.])')\n",
    "    else:\n",
    "        pattern = re.compile(r'(?<=\\.)(\\d+)(?=\\.)')\n",
    "\n",
    "    matches = pattern.findall(name)\n",
    "\n",
    "    return tuple(map(int, matches))\n",
    "\n",
    "\n",
    "def extract_tile_numbers(tile_dict, in_dict):\n",
    "    \"\"\"\n",
    "    Extract tile numbers from .fits file names.\n",
    "\n",
    "    Args:\n",
    "        tile_dict: lists of file names from the different bands\n",
    "        in_dict: band dictionary\n",
    "\n",
    "    Returns:\n",
    "        num_lists (list): list of lists containing available tile numbers in the different bands\n",
    "    \"\"\"\n",
    "\n",
    "    num_lists = []\n",
    "    for band in np.array(list(in_dict.keys())):\n",
    "        num_lists.append(np.array([get_tile_numbers(name) for name in tile_dict[band]]))\n",
    "\n",
    "    return num_lists\n",
    "\n",
    "\n",
    "def load_available_tiles(path, in_dict):\n",
    "    \"\"\"\n",
    "    Load tile lists from disk.\n",
    "    Args:\n",
    "        path (str): path to files\n",
    "        in_dict (dict): band dictionary\n",
    "\n",
    "    Returns:\n",
    "        dictionary of available tiles for the selected bands\n",
    "    \"\"\"\n",
    "\n",
    "    band_tiles = {}\n",
    "    for band in np.array(list(in_dict.keys())):\n",
    "        tiles = np.loadtxt(os.path.join(path, f'{band}_tiles.txt'), dtype=str)\n",
    "        band_tiles[band] = tiles\n",
    "\n",
    "    return band_tiles\n",
    "\n",
    "\n",
    "def relate_coord_tile(coords=None, nums=None):\n",
    "    \"\"\"\n",
    "    Conversion between tile numbers and coordinates.\n",
    "\n",
    "    Args:\n",
    "        right ascention, declination (tuple): ra and dec coordinates\n",
    "        nums (tuple): first and second tile numbers\n",
    "\n",
    "    Returns:\n",
    "        tuple: depending on the input, return the tile numbers or the ra and dec coordinates\n",
    "    \"\"\"\n",
    "    if coords:\n",
    "        ra, dec = coords\n",
    "        xxx = ra * 2 * np.cos(np.radians(dec))\n",
    "        yyy = (dec + 90) * 2\n",
    "        return int(xxx), int(yyy)\n",
    "    else:\n",
    "        xxx, yyy = nums  # type: ignore\n",
    "        dec = yyy / 2 - 90\n",
    "        ra = xxx / 2 / np.cos(np.radians(dec))\n",
    "        return np.round(ra, 12), np.round(dec, 12)\n",
    "\n",
    "\n",
    "class TileAvailability:\n",
    "    def __init__(self, tile_nums, in_dict, at_least=False, band=None):\n",
    "        self.all_tiles = tile_nums\n",
    "        self.tile_num_sets = [set(map(tuple, tile_array)) for tile_array in self.all_tiles]\n",
    "        self.unique_tiles = sorted(set.union(*self.tile_num_sets))\n",
    "        self.availability_matrix = self._create_availability_matrix()\n",
    "        self.counts = self._calculate_counts(at_least)\n",
    "        self.band_dict = in_dict\n",
    "\n",
    "    def _create_availability_matrix(self):\n",
    "        array_shape = (len(self.unique_tiles), len(self.all_tiles))\n",
    "        availability_matrix = np.zeros(array_shape, dtype=int)\n",
    "\n",
    "        for i, tile in enumerate(self.unique_tiles):\n",
    "            for j, tile_num_set in enumerate(self.tile_num_sets):\n",
    "                availability_matrix[i, j] = int(tile in tile_num_set)\n",
    "\n",
    "        return availability_matrix\n",
    "\n",
    "    def _calculate_counts(self, at_least):\n",
    "        counts = np.sum(self.availability_matrix, axis=1)\n",
    "        bands_available, tile_counts = np.unique(counts, return_counts=True)\n",
    "\n",
    "        counts_dict = dict(zip(bands_available, tile_counts))\n",
    "\n",
    "        if at_least:\n",
    "            at_least_counts = np.zeros_like(bands_available)\n",
    "            for i, count in enumerate(bands_available):\n",
    "                at_least_counts[i] = np.sum(tile_counts[i:])\n",
    "            counts_dict = dict(zip(bands_available, at_least_counts))\n",
    "\n",
    "        return counts_dict\n",
    "\n",
    "    def get_availability(self, tile_nums):\n",
    "        try:\n",
    "            index = self.unique_tiles.index(tuple(tile_nums))\n",
    "        except ValueError:\n",
    "            logger.warning(f'Tile number {tile_nums} not available in any band.')\n",
    "            return [], []\n",
    "        except TypeError:\n",
    "            return [], []\n",
    "        bands_available = np.where(self.availability_matrix[index] == 1)[0]\n",
    "        return [list(self.band_dict.keys())[i] for i in bands_available], bands_available\n",
    "\n",
    "    def band_tiles(self, band=None):\n",
    "        tile_array = np.array(self.unique_tiles)[\n",
    "            self.availability_matrix[:, list(self.band_dict.keys()).index(band)] == 1\n",
    "        ]\n",
    "        return [tuple(tile) for tile in tile_array]\n",
    "\n",
    "    def get_tiles_for_bands(self, bands=None):\n",
    "        \"\"\"\n",
    "        Get all tiles that are available in specified bands.\n",
    "        If no bands are specified, return all unique tiles.\n",
    "\n",
    "        Args:\n",
    "            bands (str or list): Band name(s) to check for availability.\n",
    "                                 Can be a single band name or a list of band names.\n",
    "\n",
    "        Returns:\n",
    "            list: List of tuples representing the tiles available in all specified bands.\n",
    "        \"\"\"\n",
    "        if bands is None:\n",
    "            return self.unique_tiles\n",
    "\n",
    "        if isinstance(bands, str):\n",
    "            bands = [bands]\n",
    "\n",
    "        try:\n",
    "            band_indices = [list(self.band_dict.keys()).index(band) for band in bands]\n",
    "        except ValueError as e:\n",
    "            logger.error(f'Invalid band name: {e}')\n",
    "            return []\n",
    "\n",
    "        # Get tiles available in all specified bands\n",
    "        available_tiles = np.where(self.availability_matrix[:, band_indices].all(axis=1))[0]\n",
    "\n",
    "        return [self.unique_tiles[i] for i in available_tiles]\n",
    "\n",
    "    def stats(self, band=None):\n",
    "        logger.info('Number of currently available tiles per band:')\n",
    "        max_band_name_length = max(map(len, self.band_dict.keys()))  # for output format\n",
    "        for band_name, count in zip(\n",
    "            self.band_dict.keys(), np.sum(self.availability_matrix, axis=0)\n",
    "        ):\n",
    "            logger.info(f'{band_name.ljust(max_band_name_length)}: {count}')\n",
    "\n",
    "        logger.info('Number of tiles available in different bands:')\n",
    "        for bands_available, count in sorted(self.counts.items(), reverse=True):\n",
    "            logger.info(f'In {bands_available} bands: {count}')\n",
    "\n",
    "        logger.info(f'Number of unique tiles available: {len(self.unique_tiles)}')\n",
    "\n",
    "        if band:\n",
    "            logger.info(f'Number of tiles available in combinations containing the {band}-band:\\n')\n",
    "\n",
    "            all_bands = list(self.band_dict.keys())\n",
    "            all_combinations = []\n",
    "            for r in range(1, len(all_bands) + 1):\n",
    "                all_combinations.extend(combinations(all_bands, r))\n",
    "            combinations_w_r = [x for x in all_combinations if band in x]\n",
    "\n",
    "            for band_combination in combinations_w_r:\n",
    "                band_combination_str = ''.join([str(x).split('-')[-1] for x in band_combination])\n",
    "                band_indices = [\n",
    "                    list(self.band_dict.keys()).index(band_c) for band_c in band_combination\n",
    "                ]\n",
    "                common_tiles = np.sum(self.availability_matrix[:, band_indices].all(axis=1))\n",
    "                logger.info(f'{band_combination_str}: {common_tiles}')\n",
    "\n",
    "\n",
    "class TileWCS:\n",
    "    \"\"\"\n",
    "    Class to create a WCS object for a tile.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, wcs_keywords={}):\n",
    "        wcs_keywords.update(\n",
    "            {\n",
    "                'NAXIS': 2,\n",
    "                'CTYPE1': 'RA---TAN',\n",
    "                'CTYPE2': 'DEC--TAN',\n",
    "                'CRVAL1': 0,\n",
    "                'CRVAL2': 0,\n",
    "                'CRPIX1': 5000.0,\n",
    "                'CRPIX2': 5000.0,\n",
    "                'CD1_1': -5.160234650248e-05,\n",
    "                'CD1_2': 0.0,\n",
    "                'CD2_1': 0.0,\n",
    "                'CD2_2': 5.160234650248e-05,\n",
    "                'NAXIS1': 10000,\n",
    "                'NAXIS2': 10000,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.wcs_tile = WCS(wcs_keywords)\n",
    "\n",
    "    def set_coords(self, coords):\n",
    "        self.wcs_tile.wcs.crval = [coords[0], coords[1]]\n",
    "\n",
    "\n",
    "def find_all_tiles(tiles, coords, tile_info_dir, loaded_tree=None):\n",
    "    \"\"\"\n",
    "    Find all tiles containing a given coordinate (up to 4).\n",
    "\n",
    "    Args:\n",
    "        tiles (list): list of tile numbers as tuples\n",
    "        coords (list): ra, dec of object to query\n",
    "        tile_info_dir (str): path to save and load the tree\n",
    "        loaded_tree: pre-loaded KD-tree (optional)\n",
    "\n",
    "    Returns:\n",
    "        list: list of tile number tuples that contain the coordinate\n",
    "    \"\"\"\n",
    "    # Only load the tree if it wasn't provided\n",
    "    if loaded_tree is None:\n",
    "        loaded_tree = joblib.load(os.path.join(tile_info_dir, 'kdtree_xyz.joblib'))\n",
    "    coord_c = SkyCoord(coords[0], coords[1], unit='deg', frame='icrs')\n",
    "    coord_xyz = coord_c.cartesian.xyz.value\n",
    "\n",
    "    # Query 4 nearest neighbors since that's the maximum by your survey design\n",
    "    dists, indices = loaded_tree.query(coord_xyz, k=4)\n",
    "\n",
    "    matching_tiles = []\n",
    "    wcs = TileWCS()\n",
    "\n",
    "    for idx in indices:\n",
    "        tile_nums = tiles[idx]\n",
    "        wcs.set_coords(relate_coord_tile(nums=tile_nums))\n",
    "        if wcs.wcs_tile.footprint_contains(coord_c):\n",
    "            matching_tiles.append(tile_nums)\n",
    "\n",
    "    return matching_tiles\n",
    "\n",
    "\n",
    "def match_coordinates(query_ra, query_dec, catalog_ra, catalog_dec, max_separation=5.0):\n",
    "    \"\"\"Match query coordinates to catalog entries within a maximum separation.\n",
    "\n",
    "    Args:\n",
    "        query_ra (float or array-like): Right ascension of query position(s) in degrees.\n",
    "        query_dec (float or array-like): Declination of query position(s) in degrees.\n",
    "        catalog_ra (array-like): Right ascension values of catalog in degrees.\n",
    "        catalog_dec (array-like): Declination values of catalog in degrees.\n",
    "        max_separation (float, optional): Maximum separation in arcseconds. Defaults to 5.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - match_mask: Boolean array indicating which catalog entries match the query\n",
    "            - catalog_indices: Indices of matching catalog entries\n",
    "    \"\"\"\n",
    "    # Convert inputs to arrays\n",
    "    query_ra_array = np.atleast_1d(query_ra)\n",
    "    query_dec_array = np.atleast_1d(query_dec)\n",
    "    catalog_ra_array = np.atleast_1d(catalog_ra)\n",
    "    catalog_dec_array = np.atleast_1d(catalog_dec)\n",
    "\n",
    "    # Handle empty inputs\n",
    "    if len(query_ra_array) == 0 or len(catalog_ra_array) == 0:\n",
    "        return np.zeros(len(catalog_ra_array), dtype=bool), np.array([], dtype=int)\n",
    "\n",
    "    # Create SkyCoord objects\n",
    "    query_coords = SkyCoord(query_ra_array, query_dec_array, unit='deg', frame='icrs')\n",
    "    catalog_coords = SkyCoord(catalog_ra_array, catalog_dec_array, unit='deg', frame='icrs')\n",
    "\n",
    "    # For each catalog coordinate, find the closest query coordinate\n",
    "    idx, d2d, _ = catalog_coords.match_to_catalog_sky(query_coords)\n",
    "\n",
    "    # Create mask for matches within separation limit\n",
    "    mask = d2d.arcsec <= max_separation\n",
    "\n",
    "    return mask, idx\n",
    "\n",
    "\n",
    "def detect_anomaly(\n",
    "    image,\n",
    "    zero_threshold=0.005,\n",
    "    min_size=50,\n",
    "    replace_anomaly=True,\n",
    "    dilate_mask=True,\n",
    "    dilation_iters=1,\n",
    "    band='cfis_lsb-r',\n",
    "):\n",
    "    # replace nan values with zeros\n",
    "    image[np.isnan(image)] = 0.0\n",
    "\n",
    "    # Perform a 2D Discrete Wavelet Transform using Haar wavelets\n",
    "    coeffs = pywt.dwt2(image, 'haar')\n",
    "    cA, (cH, cV, cD) = coeffs  # Decomposition into approximation and details\n",
    "\n",
    "    # Create binary masks where wavelet coefficients are below the threshold\n",
    "    mask_horizontal = np.abs(cH) <= zero_threshold\n",
    "    mask_vertical = np.abs(cV) <= zero_threshold\n",
    "    mask_diagonal = np.abs(cD) <= zero_threshold\n",
    "\n",
    "    masks = [mask_diagonal, mask_horizontal, mask_vertical]\n",
    "\n",
    "    global_mask = np.zeros_like(image, dtype=bool)\n",
    "    component_masks = np.zeros((3, cA.shape[0], cA.shape[1]), dtype=bool)\n",
    "    anomalies = np.zeros(3, dtype=bool)\n",
    "    for i, mask in enumerate(masks):\n",
    "        # Apply connected-component labeling to find connected regions in the mask\n",
    "        labeled_array, num_features = label(mask)  # type: ignore\n",
    "\n",
    "        # Calculate the sizes of all components\n",
    "        component_sizes = np.bincount(labeled_array.ravel())\n",
    "\n",
    "        anomaly_detected = np.any(component_sizes[1:] >= min_size)\n",
    "        anomalies[i] = anomaly_detected\n",
    "\n",
    "        if not anomaly_detected:\n",
    "            continue\n",
    "\n",
    "        # Prepare to accumulate a total mask\n",
    "        total_feature_mask = np.zeros_like(image, dtype=bool)\n",
    "\n",
    "        # Loop through all labels to find significant components\n",
    "        for component_label in range(1, num_features + 1):  # Start from 1 to skip background\n",
    "            if component_sizes[component_label] >= min_size:\n",
    "                # Create a binary mask for this component\n",
    "                component_mask = labeled_array == component_label\n",
    "                # add component mask to component masks\n",
    "                component_masks[i] |= component_mask\n",
    "                # Upscale the mask to match the original image dimensions\n",
    "                upscaled_mask = np.kron(component_mask, np.ones((2, 2), dtype=bool))\n",
    "                # Accumulate the upscaled feature mask\n",
    "                total_feature_mask |= upscaled_mask\n",
    "\n",
    "        # Accumulate global mask\n",
    "        global_mask |= total_feature_mask\n",
    "        # Dilate the masks to catch some odd pixels on the outskirts of the anomaly\n",
    "        if dilate_mask:\n",
    "            global_mask = binary_dilation(global_mask, iterations=dilation_iters)\n",
    "            for j, comp_mask in enumerate(component_masks):\n",
    "                component_masks[j] = binary_dilation(comp_mask, iterations=dilation_iters)\n",
    "    # Replace the anomaly with zeros\n",
    "    if replace_anomaly:\n",
    "        image[global_mask] = 0.0\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_channels(\n",
    "    img,\n",
    "    scaling_type='asinh',\n",
    "    stretch=0.008,\n",
    "    Q=7.0,\n",
    "    gamma=0.25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an RGB image from three bands of data preserving relative channel intensities.\n",
    "    Handles channels that are all zeros.\n",
    "    \"\"\"\n",
    "    frac = 0.1\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        red = img[:, :, 0]\n",
    "        green = img[:, :, 1]\n",
    "        blue = img[:, :, 2]\n",
    "\n",
    "        # Check for zero channels\n",
    "        red_is_zero = np.all(red == 0)\n",
    "        green_is_zero = np.all(green == 0)\n",
    "        blue_is_zero = np.all(blue == 0)\n",
    "\n",
    "        # Compute average intensity before scaling choice (avoiding zero channels)\n",
    "        nonzero_channels = []\n",
    "        if not red_is_zero:\n",
    "            nonzero_channels.append(red)\n",
    "        if not green_is_zero:\n",
    "            nonzero_channels.append(green)\n",
    "        if not blue_is_zero:\n",
    "            nonzero_channels.append(blue)\n",
    "\n",
    "        if nonzero_channels:\n",
    "            i_mean = sum(nonzero_channels) / len(nonzero_channels)\n",
    "        else:\n",
    "            i_mean = np.zeros_like(red)  # All channels are zero\n",
    "\n",
    "        if scaling_type == 'asinh':\n",
    "            # Apply asinh scaling only to non-zero channels\n",
    "            if not red_is_zero:\n",
    "                red = (\n",
    "                    red * np.arcsinh(Q * i_mean / stretch) * frac / (np.arcsinh(frac * Q) * i_mean)\n",
    "                )\n",
    "            if not green_is_zero:\n",
    "                green = (\n",
    "                    green\n",
    "                    * np.arcsinh(Q * i_mean / stretch)\n",
    "                    * frac\n",
    "                    / (np.arcsinh(frac * Q) * i_mean)\n",
    "                )\n",
    "            if not blue_is_zero:\n",
    "                blue = (\n",
    "                    blue * np.arcsinh(Q * i_mean / stretch) * frac / (np.arcsinh(frac * Q) * i_mean)\n",
    "                )\n",
    "        elif scaling_type == 'linear':\n",
    "            # Apply linear scaling without normalization\n",
    "            if not red_is_zero:\n",
    "                red = red * stretch\n",
    "            if not green_is_zero:\n",
    "                green = green * stretch\n",
    "            if not blue_is_zero:\n",
    "                blue = blue * stretch\n",
    "        else:\n",
    "            raise ValueError(f'Unknown scaling type: {scaling_type}')\n",
    "\n",
    "        # Apply gamma correction only to non-zero channels\n",
    "        if gamma is not None:\n",
    "            if not red_is_zero:\n",
    "                red_mask = abs(red) <= 1e-9\n",
    "                red = np.sign(red) * (abs(red) ** gamma)  # Preserve sign\n",
    "                red[red_mask] = 0\n",
    "\n",
    "            if not green_is_zero:\n",
    "                green_mask = abs(green) <= 1e-9\n",
    "                green = np.sign(green) * (abs(green) ** gamma)\n",
    "                green[green_mask] = 0\n",
    "\n",
    "            if not blue_is_zero:\n",
    "                blue_mask = abs(blue) <= 1e-9\n",
    "                blue = np.sign(blue) * (abs(blue) ** gamma)\n",
    "                blue[blue_mask] = 0\n",
    "\n",
    "        result = np.stack([red, green, blue], axis=-1).astype(np.float32)\n",
    "    return result\n",
    "\n",
    "\n",
    "def adjust_flux_with_zp(flux, current_zp, standard_zp):\n",
    "    adjusted_flux = flux * 10 ** (-0.4 * (current_zp - standard_zp))\n",
    "    return adjusted_flux\n",
    "\n",
    "\n",
    "def preprocess_cutout(\n",
    "    cutout,\n",
    "    scaling='asinh',\n",
    "    Q=7,\n",
    "    stretch=125,\n",
    "    gamma=0.25,\n",
    "    mode='vis',\n",
    "):\n",
    "    \"\"\"\n",
    "    Create an RGB image from the cutout data and save or plot it.\n",
    "\n",
    "    Args:\n",
    "        cutout (numpy.ndarray): cutout data\n",
    "        scaling (str, optional): scaling type. Defaults to 'asinh'. Valid options are 'linear' or 'asinh'.\n",
    "        Q (float, optional): softening parameter for asinh scaling. Defaults to 7.\n",
    "        stretch (float, optional): scaling factor. Defaults to 125.\n",
    "        gamma (float, optional): gamma correction factor. Defaults to 0.25.\n",
    "        mode (str, optional): mode of operation. Defaults to 'training'. Valid options are 'training' or 'vis'. Fills missing channels for visualization.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: preprocessed image cutout\n",
    "    \"\"\"\n",
    "\n",
    "    # Define warning filter for specific warnings\n",
    "    warnings.filterwarnings(\n",
    "        'ignore', category=RuntimeWarning, message='invalid value encountered in log'\n",
    "    )\n",
    "    warnings.filterwarnings(\n",
    "        'ignore', category=RuntimeWarning, message='invalid value encountered in power'\n",
    "    )\n",
    "    warnings.filterwarnings(\n",
    "        'ignore', category=RuntimeWarning, message='invalid value encountered in cast'\n",
    "    )\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning, message='divide by zero encountered')\n",
    "    warnings.filterwarnings(\n",
    "        'ignore',\n",
    "        category=RuntimeWarning,\n",
    "        message='RuntimeWarning: invalid value encountered in divide',\n",
    "    )\n",
    "\n",
    "    def local_warn_handler(message, category, filename, lineno, file=None, line=None):\n",
    "        if category in [RuntimeWarning, UserWarning]:  # Filter specific warning types\n",
    "            # Custom message with context about the image\n",
    "            log = f'Warning: {filename}:{lineno}: {category.__name__}: {message}'\n",
    "            logging.warning(log)  # Log the warning with contextual info\n",
    "        else:\n",
    "            # Let other warnings through normally\n",
    "            warnings.showwarning_default(message, category, filename, lineno, file, line)\n",
    "\n",
    "    # Store the default warning handler\n",
    "    warnings.showwarning_default = warnings.showwarning\n",
    "    # Set our custom handler\n",
    "    warnings.showwarning = local_warn_handler\n",
    "\n",
    "    # Use context manager for temporary warning suppression\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', category=RuntimeWarning)\n",
    "\n",
    "    # map out bands to RGB\n",
    "    cutout_red = cutout[2]  # i-band\n",
    "    cutout_green = cutout[1]  # r-band\n",
    "    cutout_blue = cutout[0]  # g-band\n",
    "\n",
    "    # adjust zero-point for the g-band\n",
    "    if np.count_nonzero(cutout_blue) > 0:\n",
    "        cutout_blue = adjust_flux_with_zp(cutout_blue, 27.0, 30.0)\n",
    "\n",
    "    # replace anomalies\n",
    "    cutout_red = detect_anomaly(cutout_red)\n",
    "    cutout_green = detect_anomaly(cutout_green)\n",
    "    cutout_blue = detect_anomaly(cutout_blue)\n",
    "\n",
    "    # synthesize missing channel from the existing ones\n",
    "    # longest valid wavelength is mapped to red, middle to green, shortest to blue\n",
    "    if mode == 'vis':\n",
    "        if np.count_nonzero(cutout_red > 1e-10) == 0:\n",
    "            cutout_red = cutout_green\n",
    "            cutout_green = (cutout_green + cutout_blue) / 2\n",
    "        elif np.count_nonzero(cutout_green > 1e-10) == 0:\n",
    "            cutout_green = (cutout_red + cutout_blue) / 2\n",
    "        elif np.count_nonzero(cutout_blue > 1e-10) == 0:\n",
    "            cutout_blue = cutout_red\n",
    "            cutout_red = (cutout_red + cutout_green) / 2\n",
    "\n",
    "    rgb = np.stack([cutout_red, cutout_green, cutout_blue], axis=-1)\n",
    "\n",
    "    # Create RGB image\n",
    "    img_rgb = process_channels(\n",
    "        rgb,\n",
    "        scaling_type=scaling,\n",
    "        stretch=stretch,\n",
    "        Q=Q,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    # restore original cutout shape (channel, cutout_size, cutout_size)\n",
    "    img_rgb = np.moveaxis(img_rgb, -1, 0)\n",
    "\n",
    "    # Restore default warning behavior after function completes\n",
    "    warnings.showwarning = warnings.showwarning_default\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def get_cutout_data(\n",
    "    avail, main_dir, data_dir, tile_info_dir, coords=None, df=None, ra_key='ra', dec_key='dec'\n",
    "):\n",
    "    \"\"\"\n",
    "    Get cutout data with highest prediction score for given coordinates,\n",
    "    optimized to read each tile's H5 file only once.\n",
    "    \"\"\"\n",
    "    available_tiles = avail.unique_tiles\n",
    "\n",
    "    # Process input coordinates\n",
    "    if coords is not None:\n",
    "        ra_list = [coords[0]]\n",
    "        dec_list = [coords[1]]\n",
    "    elif df is not None:\n",
    "        ra_list = df[ra_key].values\n",
    "        dec_list = df[dec_key].values\n",
    "    else:\n",
    "        raise ValueError('Either coords or df must be provided')\n",
    "\n",
    "    # Create a list of all coordinates\n",
    "    all_coords = list(zip(ra_list, dec_list))\n",
    "\n",
    "    # Map tiles to the coordinates they might contain\n",
    "    tile_to_coords = {}\n",
    "\n",
    "    # Load the KD-tree once instead of for each coordinate\n",
    "    kdtree_path = os.path.join(tile_info_dir, 'kdtree_xyz.joblib')\n",
    "    loaded_tree = joblib.load(kdtree_path)\n",
    "\n",
    "    # For each coordinate, find all potential tiles\n",
    "    for coord_idx, (ra, dec) in enumerate(all_coords):\n",
    "        matching_tiles = find_all_tiles(available_tiles, (ra, dec), tile_info_dir, loaded_tree)\n",
    "\n",
    "        for tile_nums in matching_tiles:\n",
    "            tile_key = (tile_nums[0], tile_nums[1])\n",
    "            if tile_key not in tile_to_coords:\n",
    "                tile_to_coords[tile_key] = []\n",
    "            tile_to_coords[tile_key].append(coord_idx)\n",
    "\n",
    "    # Initialize arrays for best matches\n",
    "    num_coords = len(all_coords)\n",
    "    best_cutouts = [None] * num_coords\n",
    "    best_preds = [-1] * num_coords\n",
    "    best_tiles = [None] * num_coords\n",
    "\n",
    "    # Process each tile\n",
    "    for tile_nums, coord_indices in tile_to_coords.items():\n",
    "        tile_dir = f'{str(tile_nums[0]).zfill(3)}_{str(tile_nums[1]).zfill(3)}'\n",
    "        h5_file = f'{tile_dir}_matched_cutouts_full_res_final.h5'\n",
    "        h5_path = os.path.join(data_dir, tile_dir, 'gri', h5_file)\n",
    "\n",
    "        if not os.path.exists(h5_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Read the H5 file ONCE for all coordinates in this tile\n",
    "            cutout_data = read_h5(h5_path)\n",
    "            h5_ra = cutout_data['ra']\n",
    "            h5_dec = cutout_data['dec']\n",
    "            h5_images = cutout_data['images']\n",
    "            h5_preds = cutout_data['zoobot_pred']\n",
    "\n",
    "            # Process each coordinate for this tile\n",
    "            for coord_idx in coord_indices:\n",
    "                ra, dec = all_coords[coord_idx]\n",
    "\n",
    "                # Find matches for this coordinate\n",
    "                match_bool, _ = match_coordinates(ra, dec, h5_ra, h5_dec, max_separation=5.0)\n",
    "\n",
    "                if np.any(match_bool):\n",
    "                    matched_preds = h5_preds[match_bool]\n",
    "                    if len(matched_preds) > 0:\n",
    "                        # Find highest prediction\n",
    "                        max_idx = np.argmax(matched_preds)\n",
    "                        max_pred = matched_preds[max_idx]\n",
    "\n",
    "                        # Update if better than current best\n",
    "                        if max_pred > best_preds[coord_idx]:\n",
    "                            best_preds[coord_idx] = max_pred\n",
    "                            # Get indices of matches\n",
    "                            matched_indices = np.where(match_bool)[0]\n",
    "                            # Get cutout with max prediction\n",
    "                            max_cutout_idx = matched_indices[max_idx]\n",
    "                            best_cutouts[coord_idx] = h5_images[max_cutout_idx : max_cutout_idx + 1]\n",
    "                            best_tiles[coord_idx] = tile_dir\n",
    "        except Exception as e:\n",
    "            print(f'Error processing tile {tile_dir}: {e}')\n",
    "\n",
    "    # Create index maps and arrays for return\n",
    "    matched_indices = []\n",
    "    unmatched_indices = []\n",
    "\n",
    "    # Collect matched and unmatched indices and print notifications\n",
    "    for i, (ra, dec) in enumerate(all_coords):\n",
    "        if best_preds[i] > -1:\n",
    "            matched_indices.append(i)\n",
    "        else:\n",
    "            print(f'No match found for object at RA/Dec: {ra:.4f}, {dec:.4f}')\n",
    "            unmatched_indices.append(i)\n",
    "\n",
    "    # Create output arrays\n",
    "    if matched_indices:\n",
    "        final_cutouts = np.concatenate([best_cutouts[i] for i in matched_indices], axis=0)\n",
    "        final_preds = np.array([best_preds[i] for i in matched_indices])\n",
    "        final_tiles = np.array([best_tiles[i] for i in matched_indices])\n",
    "    else:\n",
    "        final_cutouts = np.array([])\n",
    "        final_preds = np.array([])\n",
    "        final_tiles = np.array([])\n",
    "\n",
    "    # Create mapping from original indices to match indices\n",
    "    index_map = {}\n",
    "    for output_idx, orig_idx in enumerate(matched_indices):\n",
    "        index_map[orig_idx] = output_idx\n",
    "\n",
    "    # Also return the original coordinates and the index mapping\n",
    "    return final_cutouts, final_preds, final_tiles, all_coords, index_map\n",
    "\n",
    "\n",
    "def plot_cutouts(\n",
    "    cutouts,\n",
    "    preds,\n",
    "    all_coords,\n",
    "    index_map,\n",
    "    mode='grid',\n",
    "    figsize=None,\n",
    "    save_path=None,\n",
    "    show_plot=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Display galaxy cutouts with prediction probabilities.\n",
    "    Shows placeholders for missing matches in their original positions.\n",
    "\n",
    "    Args:\n",
    "        cutouts: Numpy array of image cutouts for matched objects\n",
    "        preds: Numpy array of prediction probabilities for matched objects\n",
    "        all_coords: List of all (ra, dec) coordinates in original order\n",
    "        index_map: Dictionary mapping original indices to positions in cutouts/preds arrays\n",
    "        mode: 'grid' or 'channel' to select display format\n",
    "        figsize: Optional tuple for figure size (width, height)\n",
    "        save_path: Optional path to save the figure\n",
    "        show_plot: Whether to show the plot and return the figure object\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure object if show_plot is True\n",
    "    \"\"\"\n",
    "    n_total = len(all_coords)\n",
    "\n",
    "    if n_total == 0:\n",
    "        print('No coordinates to display.')\n",
    "        return None\n",
    "\n",
    "    # Prepare images in the original coordinate order\n",
    "    processed_images = []\n",
    "    display_preds = []\n",
    "\n",
    "    # Process each original coordinate, either showing the match or a placeholder\n",
    "    for orig_idx, (ra, dec) in enumerate(all_coords):\n",
    "        if orig_idx in index_map:\n",
    "            # This coordinate has a match - use the actual cutout\n",
    "            match_idx = index_map[orig_idx]\n",
    "            img_rgb = preprocess_cutout(\n",
    "                cutouts[match_idx], scaling='asinh', Q=7, stretch=125, gamma=0.25, mode='vis'\n",
    "            )\n",
    "            img = np.moveaxis(img_rgb, 0, -1)\n",
    "            img = np.clip(img, 0, 1)\n",
    "            processed_images.append(img)\n",
    "            display_preds.append(preds[match_idx])\n",
    "        else:\n",
    "            # No match for this coordinate - use a placeholder\n",
    "            placeholder = np.ones((64, 64, 3)) * 0.8  # Light gray\n",
    "            processed_images.append(placeholder)\n",
    "            display_preds.append(None)  # None indicates no match\n",
    "\n",
    "    if mode.lower() == 'grid':\n",
    "        # Calculate grid dimensions\n",
    "        n_cols = min(5, n_total)  # Max 5 columns\n",
    "        n_rows = (n_total + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "        if figsize is None:\n",
    "            figsize = (3 * n_cols, 3 * n_rows)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "\n",
    "        # Handle different axis array shapes efficiently\n",
    "        axes = np.atleast_2d(axes)\n",
    "\n",
    "        # Display each cutout in original order\n",
    "        for idx in range(n_total):\n",
    "            i, j = divmod(idx, n_cols)\n",
    "            ax = axes[i, j]\n",
    "            ax.imshow(processed_images[idx], origin='lower', aspect='equal')\n",
    "\n",
    "            if display_preds[idx] is None:  # No match\n",
    "                ra, dec = all_coords[idx]\n",
    "                ax.text(\n",
    "                    32,\n",
    "                    32,\n",
    "                    'No match',\n",
    "                    fontsize=12,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    color='red',\n",
    "                    weight='bold',\n",
    "                )\n",
    "                ax.set_xlabel(f'RA={ra:.4f}, Dec={dec:.4f}', fontsize=10)\n",
    "            else:\n",
    "                ax.set_xlabel(f'{display_preds[idx]:.2f}', fontsize=15)\n",
    "\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # Hide empty subplots\n",
    "        for idx in range(n_total, n_rows * n_cols):\n",
    "            i, j = divmod(idx, n_cols)\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "        plt.tight_layout(pad=0.5)\n",
    "\n",
    "    elif mode.lower() == 'channel':\n",
    "        if figsize is None:\n",
    "            figsize = (12, 3 * n_total)\n",
    "\n",
    "        # Create figure without specifying DPI\n",
    "        fig, axes = plt.subplots(n_total, 4, figsize=figsize, constrained_layout=True)\n",
    "\n",
    "        # Handle case with single cutout\n",
    "        axes = np.atleast_2d(axes)\n",
    "\n",
    "        # Set column headers once\n",
    "        col_titles = ['Red', 'Green', 'Blue', 'RGB']\n",
    "        for j, title in enumerate(col_titles):\n",
    "            if n_total > 0:  # Only add titles if we have items to display\n",
    "                axes[0, j].set_title(title, fontsize=18, fontweight='bold', pad=10)\n",
    "\n",
    "        # Process and display all cutouts and placeholders in original order\n",
    "        for i in range(n_total):\n",
    "            img = processed_images[i]\n",
    "\n",
    "            if display_preds[i] is None:  # No match\n",
    "                ra, dec = all_coords[i]\n",
    "\n",
    "                # Display placeholder in all channels\n",
    "                for j in range(4):\n",
    "                    axes[i, j].imshow(img, cmap='gray', origin='lower', aspect='equal')\n",
    "                    axes[i, j].set_xticks([])\n",
    "                    axes[i, j].set_yticks([])\n",
    "\n",
    "                # Add \"No match\" text ONLY to RGB panel\n",
    "                axes[i, 3].text(\n",
    "                    32,\n",
    "                    32,\n",
    "                    'No match',\n",
    "                    fontsize=12,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    color='red',\n",
    "                    weight='bold',\n",
    "                )\n",
    "\n",
    "                # Add coordinates as label\n",
    "                axes[i, 0].text(\n",
    "                    -0.02,\n",
    "                    0.5,\n",
    "                    f'RA={ra:.4f}\\nDec={dec:.4f}',\n",
    "                    rotation=90,\n",
    "                    verticalalignment='center',\n",
    "                    horizontalalignment='right',\n",
    "                    transform=axes[i, 0].transAxes,\n",
    "                    fontsize=10,\n",
    "                )\n",
    "            else:\n",
    "                # Display individual channels for matched cutouts\n",
    "                for j in range(3):  # R, G, B channels\n",
    "                    axes[i, j].imshow(img[:, :, j], cmap='gray', origin='lower', aspect='equal')\n",
    "                    axes[i, j].set_xticks([])\n",
    "                    axes[i, j].set_yticks([])\n",
    "\n",
    "                # Display RGB image\n",
    "                axes[i, 3].imshow(img, origin='lower', aspect='equal')\n",
    "                axes[i, 3].set_xticks([])\n",
    "                axes[i, 3].set_yticks([])\n",
    "\n",
    "                # Add probability text\n",
    "                axes[i, 0].text(\n",
    "                    -0.02,\n",
    "                    0.5,\n",
    "                    f'{display_preds[i]:.2f}',\n",
    "                    rotation=90,\n",
    "                    verticalalignment='center',\n",
    "                    horizontalalignment='right',\n",
    "                    transform=axes[i, 0].transAxes,\n",
    "                    fontsize=15,\n",
    "                )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}. Use 'grid' or 'channel'.\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    if show_plot:\n",
    "        return fig\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408070f-a58e-4d64-9c58-7a180a69ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/arc/projects/unions/ssl/data/raw/tiles/dwarforge'\n",
    "main_dir = '/arc/home/heestersnick/dwarforge'\n",
    "table_dir = os.path.join(main_dir, 'tables')\n",
    "figure_dir = os.path.join(main_dir, 'figures')\n",
    "tile_info_dir = os.path.join(main_dir, 'tile_info')\n",
    "master = pd.read_parquet(os.path.join(table_dir, 'unions_master.parquet'))\n",
    "master_unknown = master[\n",
    "    master['lsb'].isna() & master['class_label'].isna() & (master['in_training_data'] == 0)\n",
    "].reset_index(drop=True)\n",
    "master_unknown_high_prob = master_unknown[master_unknown['zoobot_pred'] > 0.8].reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58add69a-e858-4445-8b08-65567599a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = master_unknown_high_prob[:40].reset_index(drop=True)\n",
    "\n",
    "# define the bands to consider\n",
    "considered_bands = ['whigs-g', 'cfis_lsb-r', 'ps-i']\n",
    "# create a dictionary with the bands to consider\n",
    "band_dict_incl = {key: band_dictionary.get(key) for key in considered_bands}\n",
    "# get all available tile numbers in the specified bands\n",
    "all_bands = extract_tile_numbers(\n",
    "    load_available_tiles(tile_info_dir, band_dict_incl), band_dict_incl\n",
    ")\n",
    "# create the tile availability object\n",
    "availability = TileAvailability(all_bands, band_dict_incl, band=considered_bands)\n",
    "# get cutout data\n",
    "cutouts, preds, tiles_query, all_coords, index_map = get_cutout_data(\n",
    "    avail=availability,\n",
    "    main_dir=main_dir,\n",
    "    data_dir=data_dir,\n",
    "    tile_info_dir=tile_info_dir,\n",
    "    df=test_df,\n",
    ")\n",
    "# plot the cutouts\n",
    "fig = plot_cutouts(\n",
    "    cutouts, preds, all_coords, index_map, mode='grid', save_path=None, show_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82318269-7075-492a-9785-60ec622f804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_idx = 1009\n",
    "\n",
    "obj_coords = master_unknown_high_prob[['ra', 'dec']].values[obj_idx]\n",
    "obj_coords = np.array([205.6863, 47.6032])\n",
    "print(obj_coords)\n",
    "master_pred = master_unknown_high_prob['zoobot_pred'][obj_idx]\n",
    "master_tile = master_unknown_high_prob['tile'][obj_idx]\n",
    "\n",
    "test_df = master_unknown_high_prob[:20].reset_index(drop=True)\n",
    "\n",
    "test_df.loc[5, 'ra'] = 205.6863\n",
    "test_df.loc[5, 'dec'] = 47.6032\n",
    "\n",
    "test_df.loc[10, 'ra'] = 207.1622\n",
    "test_df.loc[10, 'dec'] = 43.4118\n",
    "\n",
    "# define the bands to consider\n",
    "considered_bands = ['whigs-g', 'cfis_lsb-r', 'ps-i']\n",
    "# create a dictionary with the bands to consider\n",
    "band_dict_incl = {key: band_dictionary.get(key) for key in considered_bands}\n",
    "# get all available tile numbers in the specified bands\n",
    "all_bands = extract_tile_numbers(\n",
    "    load_available_tiles(tile_info_dir, band_dict_incl), band_dict_incl\n",
    ")\n",
    "# create the tile availability object\n",
    "availability = TileAvailability(all_bands, band_dict_incl, band=considered_bands)\n",
    "# get cutout data\n",
    "start_get = time.time()\n",
    "cutouts, preds, tiles_query, all_coords, index_map = get_cutout_data(\n",
    "    avail=availability,\n",
    "    main_dir=main_dir,\n",
    "    data_dir=data_dir,\n",
    "    tile_info_dir=tile_info_dir,\n",
    "    coords=obj_coords,\n",
    ")\n",
    "print(f'Got cutout data in {(time.time() - start_get):.1f} seconds.')\n",
    "# plot the cutouts\n",
    "start = time.time()\n",
    "# save_path = os.path.join(figure_dir, 'cutout_test_300_dpi.png')\n",
    "fig = plot_cutouts(\n",
    "    cutouts, preds, all_coords, index_map, mode='channel', save_path=None, show_plot=True\n",
    ")\n",
    "print(f'Plot done in {(time.time() - start):.1f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e71f77-1bec-4b51-8148-76d6fa8e4fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
